{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_words(Z,ids,mark='o',color='blue'):\n",
    "    r=0\n",
    "    plt.scatter(Z[:,0],Z[:,1], marker=mark, c=color)\n",
    "    for label,x,y in zip(ids, Z[:,0], Z[:,1]):\n",
    "        plt.annotate(label.decode('utf8'), xy=(x,y), xytext=(-1,1), textcoords='offset points', ha= 'center', va='bottom', bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.0), arrowprops=dict(arrowstyle='-', connectionstyle='arc3,rad=0'))\n",
    "        r+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [line.rstrip() for line in io.open(filename) if line.strip()]\n",
    "charstosub = pd.DataFrame(zip([u'á', u'é', u'í', u'ó', u'ú',u'\"',u'“',u'”',u',',u'\\.',u'ñ',u'\\!',u'\\¡'],[u'a', u'e', u'i', u'o', u'u',u'',u'',u'',u'',u'',u'n',u'',u''])) \n",
    "\n",
    "for row in charstosub.iterrows():\n",
    "    data = [re.sub(row[1][0],row[1][1],line) for line in data]\n",
    "\n",
    "data = [line.lower() for line in data]   \n",
    "\n",
    "for line in data:\n",
    "    print line\n",
    "\n",
    "\n",
    "data_short = [line.split('\\t')[0] for line in data]\n",
    "key_word = [line.split('\\t')[1] for line in data]\n",
    "\n",
    "corpus = pd.DataFrame(zip(data_short,key_word))\n",
    "corpus.columns = ['oracion','clave']\n",
    "\n",
    "list(corpus['oracion'])\n",
    "sentences = list([line.split() for line in list(corpus['oracion'])])\n",
    "model = gensim.models.Word2Vec(sentences, min_count=0, size=2, window=4)\n",
    "words = model.vocab.keys()\n",
    "for line in words:\n",
    "    print line\n",
    "vectors = [model[word] for word in model.vocab]\n",
    "rep_vect = pd.concat([pd.DataFrame(words),pd.DataFrame(vectors)],axis=1)\n",
    "rep_vect.columns = ['word','vec1','vec2']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
